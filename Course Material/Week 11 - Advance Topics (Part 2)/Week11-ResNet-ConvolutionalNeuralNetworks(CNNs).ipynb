{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week11-ResNet-ConvolutionalNeuralNetworks(CNNs).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0FslCE7TeuuQ","colab_type":"text"},"source":["# Convolutional Neural Networks (CNNs)\n","\n","### Welcome to the 11th Lab of 42028: Deep Learning and CNN!\n","\n","In this  Lab/Tutorial session you will be implementing simple ResNet50 module and create a Convolutional Neural Network for image classification .\n","\n","So lets get started!\n","\n","## Tutorial:\n","Implementation of Simple ResNet50 based Micro-ResNet CNN architecture using Keras for classfication of FashionMNIST dataset.\n","\n","## Tasks for this week:\n","\n","1. Implementation of Simple ResNet50 based Mini-ResNet CNN architecture for FashionMNIST image classification using Keras API.\n","2. Train and test model\n","\n","\n","**Reference and adapted from:** https://github.com/alinarw/ResNet/blob/master/ResNet.ipynb "]},{"cell_type":"markdown","metadata":{"id":"3WpnnqodguDh","colab_type":"text"},"source":["## The ResNet Begins !"]},{"cell_type":"markdown","metadata":{"id":"rahZjYapfk0y","colab_type":"text"},"source":["### Step 1: Import required packages\n","\n","we will need tensorflow, numpy, os and keras\n"]},{"cell_type":"code","metadata":{"id":"OB0ONDu2OVEm","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers.core import Layer\n","import keras.backend as K\n","import tensorflow as tf\n","\n","from keras.models import Model\n","from keras.layers import Conv2D, MaxPool2D,  \\\n","    Dropout, Dense, Input, concatenate,      \\\n","    GlobalAveragePooling2D, AveragePooling2D,\\\n","    Flatten, BatchNormalization, Activation, Add\n","\n","from keras.layers import MaxPooling2D, Input\n","from keras.initializers import glorot_uniform\n","\n","import cv2 \n","import numpy as np \n","from keras.datasets import cifar10, fashion_mnist \n","from keras import backend as K \n","from keras.utils import np_utils\n","\n","from keras import backend as K\n","from keras.regularizers import l2\n","\n","import math \n","from keras.optimizers import SGD, Adam, Adadelta \n","from keras.callbacks import LearningRateScheduler\n","from keras.activations import relu, softmax\n","from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n","from sklearn.metrics import confusion_matrix\n","\n","from keras.utils import plot_model\n","from keras.utils.vis_utils import model_to_dot\n","from IPython.display import HTML, display, clear_output, SVG\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3rWEMlkihytK","colab_type":"text"},"source":["### Step-2: Design the Simple ResNet-50 module\n","\n","<img src='http://drive.google.com/uc?export=view&id=1spP_NXWTUqJG-Mlw9VKC3jxpgCEriYCa' alt='Conv'> \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"mx-iv1fypAlS","colab_type":"code","colab":{}},"source":["# Residual block conv(1X1) -> BN -> relu -> conv(3x3) -> bn -> relu -> conv(1x1) ->BN\n","\n","def res_block(x, filters):\n","\n","    print('Input Shape x.shape', x.shape)\n","    # Create 1X1 CONV, --> BatchNormalization --> Activation, Initialize weights with Xavier uniform initialization (glorot_uniform)\n","    conv1 = Conv2D(filters=filters, kernel_size=(1, 1), strides=(2, 2), padding='same', \n","                   kernel_initializer=glorot_uniform(seed=0))(x)\n","    bn1 = BatchNormalization()(conv1)\n","    act1 = Activation('relu')(bn1)\n","    print('conv1.shape', conv1.shape)\n","\n","    # Create 3X3 CONV, --> BatchNormalization --> Activation, Initialize weights with Xavier uniform initialization (glorot_uniform)\n","    conv2 = Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding='same', \n","                   kernel_initializer=glorot_uniform(seed=0))(act1)\n","    bn2 = BatchNormalization()(conv2)\n","    act2 = Activation('relu')(bn2)\n","    print('conv2.shape', conv2.shape)\n","\n","    # Create 1X1 CONV, --> BatchNormalization, Initialize weights with Xavier uniform initialization (glorot_uniform)\n","    conv3 = Conv2D(filters=filters, kernel_size=(1, 1), strides=(1, 1), padding='same', \n","                   kernel_initializer=glorot_uniform(seed=0))(act2)\n","    bn3 = BatchNormalization()(conv3)\n","    print('conv3.shape', conv3.shape)\n","\n","    # Create 1X1 CONV on the Input to re-shape\n","    x = Conv2D(filters=filters, kernel_size=(1, 1), strides=(2, 2), padding='same')(x)\n","\n","    out = Add()([bn3, x])\n","    \n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yb5LCr9OsOM_","colab_type":"code","colab":{}},"source":["kernel_init = keras.initializers.glorot_uniform()\n","bias_init = keras.initializers.Constant(value=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tEmXUpDmh-Z1","colab_type":"text"},"source":["### Step 3: Design a Micro-ResNet with 1 Layer of Residual Block\n","\n","<img src='http://drive.google.com/uc?export=view&id=1PITOPO_fNskYWDS6GEIGKJn-FItNuw_j' alt='Conv'>\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"LJiHGAsSsepM","colab_type":"code","colab":{}},"source":["# Define Images dimension and number of classes\n","img_rows, img_cols = 28, 28\n","input_shape = (img_rows, img_cols, 1)\n","num_classes = 10\n","\n","# Create the input layer\n","input_layer = Input(shape=(img_rows, img_cols, 1)) # Use the actual input size\n","\n","# Create 7X7X64 CONV --> BatchNormalization --> Activation \n","x = Conv2D(64, padding='same', \n","           kernel_initializer='he_normal', \n","           kernel_size=7, strides=2,\n","           )(input_layer)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","# Add MaxPOOL, 3X3, Pad: Same, Stride: 2\n","x = MaxPooling2D(pool_size=3,padding='same', strides=2)(x)\n","\n","# Add 1 ResNet block, 64 filter\n","res_block1 = res_block(x, 64)\n","print('---------block 1 end-----------')\n","\n","# Create Classifier Block\n","# Add Flatten layer\n","classifer_Block = Flatten()(res_block1)\n","\n","# Add Dense Layer, 1000 nodes, Activation - ReLU\n","classifer_Block = Dense(1000,\n","                activation='relu')(classifer_Block)\n","\n","# Add Dense Layer, 10 nodes, Activation = SoftMax\n","outputs = Dense(num_classes,\n","                activation='softmax')(classifer_Block)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoYM0CJQshM6","colab_type":"code","colab":{}},"source":["# Form the model\n","model = Model(input_layer, outputs, name='Micro_ResNet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jYRiIKEso2s","colab_type":"code","colab":{}},"source":["#Display Model Summary\n","model.summary()\n","\n","plot_model(model, to_file='model.png', show_layer_names=True, show_shapes=True, rankdir='TB')\n","SVG(model_to_dot(model, show_layer_names=True, show_shapes=True, rankdir='TB').create(prog='dot', format='svg'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g1gJI8OsOuZQ","colab_type":"text"},"source":["### Step 4: Download the Fashion-MNIST dataset using keras"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GYw81-ar201V","colab":{}},"source":["num_classes = 10 #Number of classes in the dataset\n","\n","def load_fashion_mnist_data(img_rows, img_cols):\n","\n","    # Load cifar10 training and validation sets\n","    (X_train, Y_train), (X_valid, Y_valid) = fashion_mnist.load_data()\n","    \n","    # Resize training images\n","    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:]])\n","    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:]])\n","\n","    # Transform targets to keras compatible format\n","    Y_train = np_utils.to_categorical(Y_train, num_classes)\n","    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n","    \n","    X_train = X_train.astype('float32')\n","    X_valid = X_valid.astype('float32')\n","\n","    # preprocess data\n","    X_train = X_train / 255.0\n","    X_valid = X_valid / 255.0\n","\n","    return X_train, Y_train, X_valid, Y_valid"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNZ63cL7PuzM","colab_type":"code","colab":{}},"source":["# Display the shapes of the training images\n","X_train, y_train, X_test, y_test = load_fashion_mnist_data(28, 28)\n","X_train = X_train.reshape(X_train.shape[0],28,28,1)\n","X_test = X_test.reshape(X_test.shape[0],28,28,1)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Qh2YwnckTbm","colab_type":"code","colab":{}},"source":["## Display an image from the dataset\n","import matplotlib.pyplot as plt\n","plt.imshow(X_train.reshape(X_train.shape[0], 28, 28)[100])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ryE__lGFi91_","colab_type":"text"},"source":["### Step 5: Define the Hyper-parameters, Compile the model, Start training"]},{"cell_type":"code","metadata":{"id":"H6Nt_er0Bw4T","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzqrmvfVAieb","colab_type":"code","colab":{}},"source":["#Start training the model\n","history1 = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=100)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fBNH3MM7mYJz","colab_type":"text"},"source":["### Step 6: Display Training and Validation accuracy curve"]},{"cell_type":"code","metadata":{"id":"Fdpkn4XVewUk","colab_type":"code","colab":{}},"source":["## Plot the Traning and Validation loss\n","\n","loss = history1.history['accuracy']\n","val_loss = history1.history['val_accuracy']\n","\n","epochs = range(len(loss))\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training accuracy')\n","plt.plot(epochs, val_loss, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k7CS5apfGYpa","colab_type":"code","colab":{}},"source":["scores = model.evaluate(X_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1zFbQggpTfP","colab_type":"text"},"source":["## Your task begins now!"]},{"cell_type":"markdown","metadata":{"id":"okL5nlyehYRv","colab_type":"text"},"source":["## Task 1: Design a Mini-ResNet \n","\n","### Add three ResNet50 layers in the Mico-ResNet architecture created above in the following order and configuration:\n","\n","<img src='http://drive.google.com/uc?export=view&id=1nhCprmNy2MqGM2W4De_pP2-L2tk0K5uU' alt='Conv'>\n","\n"]},{"cell_type":"code","metadata":{"id":"3RajJeyNUbqS","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ## \n","# Define Images dimension and number of classes\n","img_rows, img_cols = #Add the image rows and cols\n","input_shape =  # Define the Input shape\n","num_classes = # Define the number of Classes\n","\n","# Create the input layer\n","\n","\n","# Create 7X7X64 CONV --> BatchNormalization --> Activation \n","x =   # Add CONV Layer\n","x =   # Add Batch Normalization\n","x =   # Add Activation\n","\n","# Add MaxPOOL, 3X3, Pad: Same, Stride: 2\n","x =   # Add MaxPool\n","\n","# Add 3 ResNet block, 64 filter, 256 filters, and 512 filters\n","res_block1 = # Add ResNet Block\n","print('---------block 1 end-----------')\n","res_block2 = # Add ResNet Block\n","print('---------block 2 end-----------')\n","res_block3 = # Add ResNet Block\n","print('---------block 3 end-----------')\n","\n","# Create Classifier Block\n","# Add Flatten layer\n","classifer_Block = \n","\n","# Add Dense Layer, 1000 nodes, Activation - ReLU\n","classifer_Block =  # Add Dense Layer with ReLU and 1000 Nodes\n","\n","# Add Dense Layer, 10 nodes, Activation = SoftMax\n","outputs =  # Add Dense Layer with SoftMax and 10 Nodes\n","\n","## END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjSbOZc4U12S","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ##\n","# Create and compile the Model\n","model = \n","\n","# END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVXKF4IAU88Q","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ##\n","# Print Model Summary\n","\n","\n","# Create the Graph image and display\n","\n","\n","# END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nFJqCJSNAFHn","colab_type":"text"},"source":["## Task 2: Define the HyperParamenters, Optimzer, etc and compile model"]},{"cell_type":"code","metadata":{"id":"m43xqSKYKFgC","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ##\n","# Compile the model\n","\n","\n","# END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5njAq5rAbhV","colab_type":"text"},"source":["## Task 3: Train the Model"]},{"cell_type":"code","metadata":{"id":"USiokHx3VLJB","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ##\n","#Start training the model, USE: EPOCH=15, BATCH_SIZE=100\n","history2 = \n","\n","# END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pD3HSb4AjPr","colab_type":"text"},"source":["## Task 4: Test on Train and Test set"]},{"cell_type":"code","metadata":{"id":"PeL8Re-YVBhA","colab_type":"code","colab":{}},"source":["## WRITE YOUR CODE HERE ##\n","# Test the model on Test and Validationa dataset\n","\n","\n","\n","# END YOUR CODE ##"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_yTgda6AqDo","colab_type":"text"},"source":["## Task 5: Display the Train and Validation Accuracy curve"]},{"cell_type":"code","metadata":{"id":"HKejCK_AeaEC","colab_type":"code","colab":{}},"source":["## Plot the Traning and Validation loss\n","\n","loss = history2.history['accuracy']\n","val_loss = history2.history['val_accuracy']\n","\n","epochs = range(len(loss))\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training accuracy')\n","plt.plot(epochs, val_loss, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend()"],"execution_count":0,"outputs":[]}]}