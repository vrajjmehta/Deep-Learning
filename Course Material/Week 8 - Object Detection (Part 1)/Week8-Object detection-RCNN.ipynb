{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week8-Object detection-RCNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mamiXm5pltDZ","colab_type":"text"},"source":["# Object Detection Part - 1:  Faster R-CNN\n","\n","### Welcome to the 8th Lab of 42028: Deep Learning and CNN!\n","\n","In this  Lab/Tutorial session you will be learning how to train object detection model for custom dataset, evaluate trained model on test dataset.\n","\n","Configuration of Faster R-CNN object detector for custom dataset. \n","\n","So lets get started!\n","\n","## Tutorial:\n","1. Image annotation using LabelImg (Reference: http://labelme.csail.mit.edu/Release3.0/)\n","2. Conversion of annotation & images into tfrecords\n","3. Configuration of Faster R-CNN config model file\n","4. Training the model\n","5. Using trained model for inference\n","\n","## Tasks for this week:\n","\n","1. installation of Google Object Detection API and required packages\n","2. Conversion of images and xml into tfrecord. i.e. train tfrecord, test tfrecord\n","3. Training: Transfer learning from already trained models\n","4. Freezing a trained model and export it for inference\n"]},{"cell_type":"markdown","metadata":{"id":"4IG-E4uMo8al","colab_type":"text"},"source":["##Task-1: Installation of Google Object Detection API and required packages\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MlPAfL_VWCki","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrgipiyWnlOF","colab_type":"text"},"source":["### Step 1: Import packages\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"cZzYq6qGXOUw","colab_type":"code","colab":{}},"source":["import os\n","import re\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hgqx7vZnw4_W","colab_type":"text"},"source":["### Step 2: Initial Configuration to Select Faster R-CNN model config file and selection of other hyperparameters"]},{"cell_type":"code","metadata":{"id":"Gz2sswLyw9hZ","colab_type":"code","colab":{}},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/Tony607/object_detection_demo'\n","\n","# Number of training steps.\n","num_steps = 1000  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","\n","selected_model = 'faster_rcnn_inception_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXwYO33qxB2Y","colab_type":"code","colab":{}},"source":["%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xTGEynaxUfL","colab_type":"text"},"source":["### Step 3: Download Google Object Detection API and other dependencies"]},{"cell_type":"code","metadata":{"id":"OerFd75RoIWz","colab_type":"code","colab":{}},"source":["%cd /content\n","#!git clone --quiet https://github.com/tensorflow/models.git\n","!git clone --branch r1.13.0 --depth 1 https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xl2Xn4Mh0bqw","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"uBOCW--vh6Wn","colab_type":"text"},"source":["##Task-2: Conversion of XML annotations and images into tfrecords for training and testing datasets"]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny","colab_type":"text"},"source":["### Step 4: Prepare `tfrecord` files\n","\n","Use the following scripts to generate the `tfrecord` files.\n","```bash\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n","```"]},{"cell_type":"code","metadata":{"id":"yBr8HgvoyMUc","colab_type":"code","colab":{}},"source":["%cd {repo_dir_path}\n","\n","## WRITE YOUR CODE HERE ##\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","#-->\n","\n","# Convert test folder annotation xml files to a single csv.\n","#-->\n","\n","# Generate `train.record`\n","#-->\n","\n","# Generate `test.record`\n","#-->\n","\n","## END YOUR CODE HERE ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c24vw09_5jNI","colab_type":"code","colab":{}},"source":["test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n","train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGZqihrPiBjs","colab_type":"text"},"source":["### Step 5. Download the base model for transfer learning"]},{"cell_type":"code","metadata":{"id":"jj7_kqv6yR7D","colab_type":"code","colab":{}},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhsMMfNN25hY","colab_type":"code","colab":{}},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gs0047Qx4LIf","colab_type":"code","colab":{}},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GTJvAARCiQbm","colab_type":"text"},"source":["##Task-3: Training: Transfer learning from already trained models\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-BWSpqW6NYJE","colab_type":"text"},"source":["###Step 6: configuring a training pipeline"]},{"cell_type":"code","metadata":{"id":"551Z4gAC4uzO","colab_type":"code","colab":{}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZYoq1tq40Ak","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"098IARSk5CJk","colab_type":"code","colab":{}},"source":["\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LW5OvToX5v3Q","colab_type":"code","colab":{}},"source":["!cat {pipeline_fname}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOzfAVox6DxP","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeXwrBbnibPp","colab_type":"text"},"source":["### Step 7. Install Tensorboard to visualize the progress of training process"]},{"cell_type":"code","metadata":{"id":"JY2IwBMvyiLq","colab_type":"code","colab":{}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPSCe4VW6is7","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NcQjIax6oSu","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LfI4vNaj6zgs","colab_type":"text"},"source":["### Step: 8 Get tensorboard link"]},{"cell_type":"code","metadata":{"id":"-26O0PrC6x2O","colab_type":"code","colab":{}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STof3OBrdWUy","colab_type":"text"},"source":["### Step 9.  Training the model"]},{"cell_type":"code","metadata":{"id":"PZSdysPLcfOA","colab_type":"code","colab":{}},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQY54srv7NSL","colab_type":"code","colab":{}},"source":["!ls {model_dir}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4y32QymeiqDB","colab_type":"text"},"source":["##Task-4:  Freezing a trained model and export it for inference\n"]},{"cell_type":"markdown","metadata":{"id":"7b1cB69J7-Qh","colab_type":"text"},"source":["### Step: 10 Exporting a Trained Inference Graph"]},{"cell_type":"code","metadata":{"id":"ZhQu9lWK71fS","colab_type":"code","colab":{}},"source":["import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnHLjMbXDZ5G","colab_type":"code","colab":{}},"source":["!ls {output_directory}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rfwp6BrFC2qQ","colab_type":"text"},"source":["### Step 11: Use frozen model for inference."]},{"cell_type":"code","metadata":{"id":"4pdDFjp9DS2l","colab_type":"code","colab":{}},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmn8A9qSDjli","colab_type":"code","colab":{}},"source":["!ls -alh {pb_fname}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Maem5Yv_FCn","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xEHFCsWxFCRz","colab_type":"code","colab":{}},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GioPUIRjFDYX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}