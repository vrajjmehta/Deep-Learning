{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Handcrafted Feature Extraction_ Part-1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CQ7c8b6GDTvI","colab_type":"text"},"source":["# Handcrafted Feature Extraction: Part-1\n","\n","### Welcome to the 3rd Lab of 42028: Deep Learning and CNN!\n","\n","In the 3rd Lab/Tutorial session you will be implementing feature extraction using LBP and HOG and train SVM classifier for classification!\n","\n","So lets get started!"]},{"cell_type":"markdown","metadata":{"id":"lLT7e7X8Qv2q","colab_type":"text"},"source":["## Tasks for this week:\n","\n","1. Extraction of LBP features from fashion MNIST dataset and classification using SVM multiclass classification.\n","2. Extraction of HOG features from fashion MNIST dataset and classification using SVM multiclass classification.\n"]},{"cell_type":"markdown","metadata":{"id":"BbIYSNtghMwn","colab_type":"text"},"source":["## Task 1: Extraction of LBP features from fashion MNIST dataset and classification using SVM multiclass classification."]},{"cell_type":"markdown","metadata":{"id":"ZG24TIGxUtht","colab_type":"text"},"source":["### Step 1: Import required packages\n","\n"]},{"cell_type":"code","metadata":{"id":"Da7NhutTB9B5","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import feature # This pacakge is used for LBP feature extraction\n","from sklearn import svm # This pacakge is used for svm classification\n","from sklearn import metrics\n","%matplotlib inline\n","import cv2\n","import seaborn as sns # This pacakge is used for better visualization of data (e.g confusion matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSZZuSdDtJWl","colab_type":"text"},"source":["###  Mount the Google Drive to access the Fashion MNIST Dataset\n","\n"]},{"cell_type":"code","metadata":{"id":"X8Bke0iBtKNZ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4lQmu7vmV0pL","colab_type":"text"},"source":["### Step 2. Dataset preparation\n","\n","* ** Utility/Helper function to load Dataset, unzip it and return images and labels.**  (Do not modify)\n","\n","[**Reference**:   https://github.com/zalandoresearch/fashion-mnist](https:////github.com/zalandoresearch/fashion-mnist)"]},{"cell_type":"code","metadata":{"id":"RxzH4fC2CyPx","colab_type":"code","colab":{}},"source":["def load_mnist(path, kind='train'):\n","    import os\n","    import gzip\n","    import numpy as np\n","\n","    \"\"\"Load MNIST data from `path`\"\"\"\n","    labels_path = os.path.join(path,\n","                               '%s-labels-idx1-ubyte.gz'\n","                               % kind)\n","    images_path = os.path.join(path,\n","                               '%s-images-idx3-ubyte.gz'\n","                               % kind)\n","\n","    with gzip.open(labels_path, 'rb') as lbpath:\n","        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n","                               offset=8)\n","\n","    with gzip.open(images_path, 'rb') as imgpath:\n","        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n","                               offset=16).reshape(len(labels), 784)\n","\n","    return images, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ermpHhvbNmqS","colab_type":"code","colab":{}},"source":["cd /content/gdrive/My Drive/42028-DL-CNN-2020/Week3-Lab3/data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ii71hHBlOG-r","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_2zvPNOJWcR4","colab_type":"text"},"source":["* **  Use the utility function to load the dataset and split it into train and test.** (Do not change)\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"iwyWkNG_B-Wh","colab_type":"code","colab":{}},"source":["X_train, y_train = load_mnist('/content/gdrive/My Drive/42028-DL-CNN-2020/Week3-Lab3/data/fashion', kind='train')\n","X_test, y_test = load_mnist('/content/gdrive/My Drive/42028-DL-CNN-2020/Week3-Lab3/data/fashion', kind='t10k')\n","# initialize the label names from Fashion MNIST github repository\n","\n","labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n","\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUV58oYt1X-s","colab_type":"code","colab":{}},"source":["# The 28X28 images are flattened to feature vector of size 784\n","# There are 60,000 training examples in the training dataset\n","# There are 10,000 test sample in the testing dataset\n","print(np.shape(X_train))\n","print(np.shape(X_test))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6OLVgneIX8qe","colab_type":"text"},"source":["* ** Reshaping the feature vector back into the 28X28 image**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Ze_IBL-rrLoN","colab_type":"code","colab":{}},"source":["X_train=X_train.reshape(-1,28,28)\n","X_test=X_test.reshape(-1,28,28)\n","\n","# print the size of the result reshaped train and test data splits\n","\n","print(\"Train dataset after reshaping:{}\".format(np.shape(X_train)))\n","print(\"Test dataset after reshaping :{}\".format(np.shape(X_test)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OeDxnxJNZO2T","colab_type":"text"},"source":["### 2. Visualization of Dataset\n","\n","(Do not change)"]},{"cell_type":"code","metadata":{"id":"itQCm5P91hP4","colab_type":"code","colab":{}},"source":["# view few images and print its corresponding label\n","img_index = 10\n","fig = plt.figure()\n","ax1 = fig.add_subplot(2,2,1)\n","ax1.axis('off')\n","ax1.imshow(X_train[img_index])\n","print(labelNames[y_train[img_index]])\n","\n","ax2 = fig.add_subplot(2,2,2)\n","ax2.axis('off')\n","img_index = 1000\n","ax2.imshow(X_train[img_index])\n","print(labelNames[y_train[img_index]])\n","\n","ax2 = fig.add_subplot(2,2,3)\n","ax2.axis('off')\n","img_index = 20000\n","ax2.imshow(X_train[img_index])\n","print(labelNames[y_train[img_index]])\n","\n","ax2 = fig.add_subplot(2,2,4)\n","ax2.axis('off')\n","img_index = 30000\n","ax2.imshow(X_train[img_index])\n","print(labelNames[y_train[img_index]])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjKuOdexZzJF","colab_type":"text"},"source":["### 3. Local Binary Patterns (LBP) class definition for LBP feature extraction"]},{"cell_type":"code","metadata":{"id":"TD-TcdQP2msQ","colab_type":"code","colab":{}},"source":["class LocalBinaryPatterns:\n","\tdef __init__(self, numPoints, radius):\n","\t\t# store the number of points and radius\n","\t\tself.numPoints = numPoints\n","\t\tself.radius = radius\n"," \n","\tdef LBPfeatures(self, image, eps=1e-7):\n","\t\t# compute the Local Binary Pattern representation\n","\t\t# of the image, and then use the LBP representation\n","\t\t# to build the histogram of patterns\n","\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n","\t\t\tself.radius, method=\"uniform\")\n","    # Form the histogram\n","\t\t(hist, _) = np.histogram(lbp.ravel(),\n","\t\t\tbins=np.arange(0, self.numPoints + 3),\n","\t\t\trange=(0, self.numPoints + 2))\n"," \n","\t\t# normalize the histogram\n","\t\thist = hist.astype(\"float\")\n","\t\thist /= (hist.sum() + eps)\n"," \n","\t\t# return the histogram of Local Binary Patterns\n","\t\treturn hist"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnw-emmGcDbh","colab_type":"text"},"source":["**LBP feature extraction for the whole training dataset**"]},{"cell_type":"code","metadata":{"id":"GRyZK2Zv4N5B","colab_type":"code","colab":{}},"source":["# Create an object of LocalBinaryPatterns class and initial the parameters.\n","desc = LocalBinaryPatterns(24, 8)\n","data_train = []\n","labels_train = []\n","\n","## WRITE YOUR CODE HERE (~ 3 lines)\n","# loop over the training images\n","for img_index in range():\n","\t# load the train image, and extract LBP features\n","\timage = \n","\thist = \n","## END YOUR CODE HERE \n","\n","\t# extract the label from the image path, then update the\n","\t# label and data lists\n","\tlabels_train.append(y_train[img_index])\n","\tdata_train.append(hist)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yr9Y5J9fjem4","colab_type":"text"},"source":["### 4. Train SVM Classifier using the training dataset\n","\n","***Note: Training process may take long time ...***"]},{"cell_type":"code","metadata":{"id":"9o6z2GyEjpuU","colab_type":"code","colab":{}},"source":["# train a SVM clasifier on the training data\n","# Initialize the SVM model\n","# Use rbf Kernel, c = 100 and randon_state=42\n","\n","## WRITE YOUR CODE HERE (~ 2 lines)\n","model = svm.SVC() \n","# Start training the SVM classifier \n","model.fit()\n","## END YOUR CODE HERE \n","\n","print(np.shape(data_train))\n","print(np.shape(labels_train))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX0l_27ae-sL","colab_type":"code","colab":{}},"source":["# Check the training accuray\n","print(\"Train set Accuracy: {:.2f}\".format(model.score(data_train,labels_train)))\n","\n","# Expected training set Accuracy 0.60"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bRd4jv4_dzQJ","colab_type":"text"},"source":["### 5. Evaluation of trained SVM model on test dataset"]},{"cell_type":"code","metadata":{"id":"Mp3XXEaK4B9F","colab_type":"code","colab":{}},"source":["predictions=[]\n","predict_label=[]\n","# Exract LBP features for each test sample and classify it with the trained SVM classifier\n","\n","## WRITE YOUR CODE HERE (~ 2 lines)\n","for im_index in range(len(X_test)):\n","  imag = X_test[im_index]\n","  \n","  # Extract LBP feature\n","  histo = \n","  # Perform classification, Hint: use model.predict()\n","  prediction = \n","## END YOUR CODE HERE \n","  \n","  # Store the classfication result\n","  predictions.append(prediction)\n","  predict_label.append(y_test[im_index])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4ktOt1kgz00","colab_type":"code","colab":{}},"source":["accuracy = metrics.accuracy_score(y_test, predictions)\n","print(\"Accuracy on test dataset:\",accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXC3Fh2oAHB_","colab_type":"code","colab":{}},"source":["# plot the confusion matrix\n","cm  = metrics.confusion_matrix(y_test, predictions)\n","print(cm)\n","\n","# Plot confusion matrix using seaborn library\n","plt.figure(figsize=(9,9))\n","sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n","plt.ylabel('Actual label');\n","plt.xlabel('Predicted label');\n","all_sample_title = 'Accuracy Score: {0}'.format(accuracy)\n","plt.title(all_sample_title, size = 15);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wFngH9dR9P8","colab_type":"code","colab":{}},"source":["# Display some classification result on test samples\n","images = []\n"," \n","# randomly select a few testing fashion items\n","for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n","  # classify the clothing\n","  histog = desc.LBPfeatures(X_test[i])\n","  prediction = model.predict(histog.reshape(1, -1))\n","  label = labelNames[prediction[0]]\n","  orig_label=labelNames[y_test[i]]\n","  image = X_test[i]\n","  color = (0, 255, 0)\n","  image = cv2.merge([image] * 3)\n","  image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n","  cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50, color, 2)\n","  images.append(image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vi3fq-kqjvhP","colab_type":"code","colab":{}},"source":["np.shape(images[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyUV05UsyGdf","colab_type":"code","colab":{}},"source":["## Display the classification results\n","fig = plt.figure()\n","ax1 = fig.add_subplot(2,2,1)\n","ax1.imshow(images[1])\n","print(orig_label[:])\n","ax2 = fig.add_subplot(2,2,2)\n","ax2.imshow(images[2])\n","ax3 = fig.add_subplot(2,2,3)\n","ax3.imshow(images[3])\n","ax4 = fig.add_subplot(2,2,4)\n","ax4.imshow(images[4])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKQmbWEOkIF4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}