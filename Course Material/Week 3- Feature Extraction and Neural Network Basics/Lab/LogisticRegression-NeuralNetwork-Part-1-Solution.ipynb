{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression-NeuralNetwork-Part-1-Solution.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WAAlSUKe06dA","colab_type":"text"},"source":["# Logistic Regression using Neural Network: Part -1\n","\n","Welcome to the 3rd Lab of 42028: Deep Learning and CNN!\n","\n","In this week you will be implementing some parts of a Logistic Regression classifier using Neural Network. Specifically, you will implement the activation function, and cost/loss function.\n","\n","So lets get started!"]},{"cell_type":"markdown","metadata":{"id":"_kF22oPX-IWa","colab_type":"text"},"source":["## Binary Classification (Logistic Regression) Overview\n","\n","\n","<img src='http://drive.google.com/uc?export=view&id=1LFtuvxhDn1rbZjeuzw2uAXI6Y9I5qyaa' alt='Conv'>\n","\n","\n","\n","Activation function $a = \\sigma( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$\n","\n","Loss function $L(a, y) = -y\\log a+(1-y)\\log(1-a)$ \n","\n","\n","\n","<img src='http://drive.google.com/uc?export=view&id=1TrjdisDOCqqj0uaAC9zkPGpEAXBEtRA2' alt='Conv'>\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BcuTioANFvDd","colab_type":"text"},"source":["## Tasks: \n","\n","1. Implement the Sigmoid activation function \n","2. Implement the Log loss cost function"]},{"cell_type":"markdown","metadata":{"id":"ZC-aJw3MGySa","colab_type":"text"},"source":["# Task 1: Implement Sigmoid function\n","\n","A sigmoid function is of a form:\n","\n","$\\sigma( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$\n","\n","Let  $z=w^T x + b,$\n","\n","Hence, $\\sigma(z) = \\frac{1}{1 + e^{-(z)}}$\n","\n","\n","Write a function below to calculate $\\sigma(z)$ is Python.\n","\n","Hint:\n","\n","**exp(x)** --> Return e**x. \n","\n","\n","**Reference**: https://docs.python.org/2/library/math.html"]},{"cell_type":"code","metadata":{"id":"_V7_YUGFotZr","colab_type":"code","colab":{}},"source":["import math, numpy as np\n","def sigmoid(z):\n","    \"\"\"\n","    Calculate the sigmoid of z\n","\n","    Arguments:\n","    z --> A scalar or numpy array of any size.\n","\n","    Return:\n","    result --> sigmoid(z)\n","    \"\"\"\n","\n","    ### WRITE CODE HERE ### (1 line of code)\n","    result = 1 / (1 + math.exp(-z))\n","    ### END YOUR CODE HERE ###\n","    \n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5IcsQqNjI9px","colab_type":"text"},"source":["For, z = 0.458\n","\n","**[Expected Output]**\n","\n","sigmoid(0.458) --> 0.6125396134409151\n","\n","Execute the code given below to check to the output of your function."]},{"cell_type":"code","metadata":{"id":"BSuwkDLqIz5F","colab_type":"code","outputId":"36d887c1-31e7-4d59-a265-cdbff616aae4","executionInfo":{"status":"ok","timestamp":1585474999730,"user_tz":-660,"elapsed":1862,"user":{"displayName":"Muhammad Saqib","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_VAkrtE5jh5-64Dmvc-Qq_nX3-sSYLwhtg2E=s64","userId":"00918361658236158849"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["z=0.458\n","print(sigmoid(z))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["0.6125396134409151\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i3vQacHuKE_b","colab_type":"text"},"source":["## Task-2: Implement the negative log-likelihood loss (log loss)\n","\n","$L(a, y) = -y\\log a+(1-y)\\log(1-a)$ \n","\n","Complete the below function to calculate L(a, y) in python\n","\n","\n","**Hint**: Use np.log() for log\n","\n"]},{"cell_type":"code","metadata":{"id":"Xe60GqPQJKkY","colab_type":"code","colab":{}},"source":["def loss(a, y):\n","    \"\"\"\n","    Calculate the Loss L between actual (y) and predicted(a) value.\n","\n","    Arguments:\n","    y --> A scalar.\n","    a --> A scalar.\n","\n","    Return:\n","    result --> loss(y, a)\n","    \"\"\"\n","\n","    ### WRITE CODE HERE ### (1 line of code)\n","    result = (-y * np.log(a)) + ((1-y)*np.log(1-a))\n","    ### END YOUR CODE HERE ###\n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mIyf_68QBQd","colab_type":"code","outputId":"25999d50-778a-42a5-c793-4b19ca522878","executionInfo":{"status":"ok","timestamp":1585474999731,"user_tz":-660,"elapsed":1854,"user":{"displayName":"Muhammad Saqib","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_VAkrtE5jh5-64Dmvc-Qq_nX3-sSYLwhtg2E=s64","userId":"00918361658236158849"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(loss(0.7, 1))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["0.35667494393873245\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9BeFz7U0QHC-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}